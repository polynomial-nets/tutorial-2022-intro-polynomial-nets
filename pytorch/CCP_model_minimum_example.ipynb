{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is providing a minimum code for running MNIST classification with a CCP model (i.e. a polynomial expansion without activation functions) in *PyTorch*. \n",
    "\n",
    "\n",
    "*Details*: The model implements a fourth-degree polynomial expansion (and in particular the [CCP model](https://github.com/grigorisg9gr/polynomial_nets) from the $\\Pi$-Nets), using a hidden dimension of 16. The network is not optimized for performance reasons, but simply to introduce you to the concept of polynomial nets in PyTorch (verified with PyTorch v.1.13). \n",
    "\n",
    "For implementations that obtain state-of-the-art code with polynomial nets, please visit other respositories, such as the https://github.com/grigorisg9gr/polynomial_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size=16, image_size=28, channels_in=1, n_degree=4, bias=True, n_classes=10):\n",
    "        \"\"\"\n",
    "        This is the initialization function of the network, which in this case is a polynomial network.\n",
    "        The implementation here relies on the CCP model of $\\Pi$-nets. \n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.channels_in = channels_in\n",
    "        self.total_image_size = self.image_size * self.image_size * channels_in\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_degree = n_degree\n",
    "        for i in range(1, self.n_degree + 1):\n",
    "            setattr(self, 'U{}'.format(i), nn.Linear(self.total_image_size, self.hidden_size, bias=bias))\n",
    "        self.C = nn.Linear(self.hidden_size, self.n_classes, bias=True)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = z.view(-1, self.total_image_size)\n",
    "        out = self.U1(h)\n",
    "        for i in range(2, self.n_degree + 1):\n",
    "            out = getattr(self, 'U{}'.format(i))(h) * out + out\n",
    "        out = self.C(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model and move to device\n",
    "model = Net().to(device)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Load MNIST dataset and apply transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "    # Print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 400 == 399:\n",
    "        print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 1000:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CCP_model_minimum_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
